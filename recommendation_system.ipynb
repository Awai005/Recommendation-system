{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will build a recommender system\n",
    "\n",
    "The recommendation system I will build will be user-user based collaborative filtering and item-item based collaborative filtering and later go onto try a model based collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading both the datasets and setting the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['userId', 'questionId', 'rating', 'department']\n",
    "ratings = pd.read_excel('C:/Users/Daniel Eje/Downloads/book.xlsx', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "#ratings_test = pd.read_csv('C:/Users/User/Downloads/ua.test', sep='\\t', names=r_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>questionId</th>\n",
       "      <th>rating</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  questionId  rating  department\n",
       "0       1           1       5         NaN\n",
       "1       1           2       5         NaN\n",
       "2       1           3       0         NaN\n",
       "3       1           4       5         NaN\n",
       "4       1           5       0         NaN"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column userId contains ids' of users starting from 1, the column questionId contains ids' of questions starting from 1 and the 'rating' column contains the corresponding ratings. Let us see how many unique users and how many unique questions are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 16)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = ratings['userId'].unique().max()\n",
    "n_questions = ratings['questionId'].unique().max()\n",
    "n_users,n_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 100 users and 16 questions in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_users_test = ratings_test['userId'].unique().max()\n",
    "#n_items_test = ratings_test['questionId'].unique().max()\n",
    "#n_users_test,n_items_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating user-item matrix\n",
    "\n",
    "Now let us go ahead and create our user-item matrices, test_matrix and train_matrix which contain number of rows equal to the number of unique users and number of columns equal to the number of unique questions. The cells of this matrix are filled with the corresponding rating a user has been given based on the response to a question. If a users response has not been rated the cell is filled with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = np.zeros((n_users, n_questions))\n",
    "for line in ratings.itertuples():\n",
    "    train_matrix[line[1]-1,line[2]-1] = line[3]   \n",
    "#test_matrix = np.zeros((n_users_test, n_items_test))\n",
    "#for line in ratings_test.itertuples():\n",
    "#    test_matrix[line[1]-1,line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying user-user based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach we try is user-user based collaborative filtering. In this method, we first create a similarity matrix which specifies the similarity between two users based on the ratings they have been given to different questions. We use the cosine similarity metric which computers the dot product between the two vectors made up of the ratings of the movies they have rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (100, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.11220648, 0.04396246, ..., 0.06179228, 0.14133588,\n",
       "        0.15326384],\n",
       "       [0.11220648, 0.        , 0.0844352 , ..., 0.06280791, 0.22507911,\n",
       "        0.20006567],\n",
       "       [0.04396246, 0.0844352 , 0.        , ..., 0.08003917, 0.13492629,\n",
       "        0.1153486 ],\n",
       "       ...,\n",
       "       [0.06179228, 0.06280791, 0.08003917, ..., 0.        , 0.15924232,\n",
       "        0.19011317],\n",
       "       [0.14133588, 0.22507911, 0.13492629, ..., 0.15924232, 0.        ,\n",
       "        0.07722164],\n",
       "       [0.15326384, 0.20006567, 0.1153486 , ..., 0.19011317, 0.07722164,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity = pairwise_distances(train_matrix, metric='cosine')\n",
    "print('shape: ',user_similarity.shape)\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity matrix has the shape to 100 x 100 as expected with each cell corresponding to the similarity between two users. Now we will write a prediction function which will predict the values in the user-item(question matrix. We will only consider the top n users which are similar to a user to make predictions for that user. In the formula we normalise the ratings of users by subtracting the mean rating of a user from every rating given to the users questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\hat{x}_{k,m} =\\bar{x}_{k} + \\frac{\\sum\\limits_{u_a} sim_u(u_k, u_a) (x_{a,m} - \\bar{x}_{u_a})}{\\sum\\limits_{u_a}|sim_u(u_k, u_a)|}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_user(train_matrix, user_similarity, n_similar=100):\n",
    "    similar_n = user_similarity.argsort()[:,-n_similar:][:,::-1]\n",
    "    pred = np.zeros((n_users,n_questions))\n",
    "    for i,users in enumerate(similar_n):\n",
    "        similar_users_indexes = users\n",
    "        similarity_n = user_similarity[i,similar_users_indexes]\n",
    "        matrix_n = train_matrix[similar_users_indexes,:]\n",
    "        rated_items = similarity_n[:,np.newaxis].T.dot(matrix_n - matrix_n.mean(axis=1)[:,np.newaxis])/ similarity_n.sum()\n",
    "        pred[i,:]  = rated_items\n",
    "    return pred\n",
    "def predict_users(user_similarity): \n",
    "    sim = []\n",
    "    for i in range(0,100):\n",
    "        top_10_users = []\n",
    "        arr = user_similarity[i]\n",
    "        sorted_arr = np.sort(arr)[::-1]\n",
    "        for key in range(0,10):\n",
    "            search_key = sorted_arr[key]\n",
    "            result = np.where(arr == search_key)\n",
    "            top_user = result[0][0] + 1\n",
    "            top_10_users.append(top_user)\n",
    "        sim.append((i+1,top_10_users))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one function to find the predicted ratings and add the average rating of every user to give back the final predicted ratings. Here, we are considering the top 100 users which are similar to our user and using their ratings to predict our user's ratings.\n",
    "The other function is used to find the best match of similar users to a particular user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape  (100, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.35754813, 4.97921168, 3.94432139, ..., 3.90865566, 3.85359681,\n",
       "        3.74285658],\n",
       "       [4.82382006, 4.437079  , 3.30464807, ..., 3.39134493, 3.39008652,\n",
       "        3.24903886],\n",
       "       [5.16217343, 4.74413551, 3.7426921 , ..., 3.8205868 , 3.71265995,\n",
       "        3.58041481],\n",
       "       ...,\n",
       "       [4.90464328, 4.48148849, 3.4564079 , ..., 3.43203774, 3.45491168,\n",
       "        3.33449098],\n",
       "       [5.5297413 , 5.2031479 , 3.27524773, ..., 4.26968891, 3.8846415 ,\n",
       "        4.02905668],\n",
       "       [5.35028546, 5.02346966, 3.04844649, ..., 4.07565674, 3.82050319,\n",
       "        3.83036157]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_user_user(train_matrix,user_similarity, 100) + train_matrix.mean(axis=1)[:, np.newaxis]\n",
    "print('predictions shape ',predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_ratings = predictions[test_matrix.nonzero()]\n",
    "#test_truth = test_matrix[test_matrix.nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#math.sqrt(mean_squared_error(predicted_ratings,test_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying question-question based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will go on and try item-item based collaborative filtering. This method finds the similarity between items instead of users, exactly like the previous method using 'cosine similarity'. Using the similarity between items and the users rating for similar items, we find the predicted ratings for un-rated items. Let us make the item similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity = pairwise_distances(train_matrix.T, metric = 'cosine')\n",
    "item_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.02532057, 0.21259921, 0.09560514, 0.21442982,\n",
       "        0.28912294, 0.03698586, 0.25193276, 0.06137651, 0.10265558,\n",
       "        0.        , 0.16356582, 0.        , 0.04198024, 0.05565788,\n",
       "        0.02620876],\n",
       "       [0.02532057, 0.        , 0.25729353, 0.12365987, 0.22202895,\n",
       "        0.28793857, 0.05828233, 0.2462537 , 0.08165383, 0.12835235,\n",
       "        0.02532057, 0.19513871, 0.02532057, 0.07070561, 0.09237612,\n",
       "        0.05156929],\n",
       "       [0.21259921, 0.25729353, 0.        , 0.30816368, 0.39523168,\n",
       "        0.46087838, 0.26108654, 0.4245239 , 0.32277567, 0.31535623,\n",
       "        0.21259921, 0.31711056, 0.21259921, 0.23522575, 0.24525823,\n",
       "        0.25797033],\n",
       "       [0.09560514, 0.12365987, 0.30816368, 0.        , 0.34951384,\n",
       "        0.43604073, 0.12857747, 0.39022886, 0.18845351, 0.2240498 ,\n",
       "        0.09560514, 0.20454349, 0.09560514, 0.15245731, 0.12452867,\n",
       "        0.12808538],\n",
       "       [0.21442982, 0.22202895, 0.39523168, 0.34951384, 0.        ,\n",
       "        0.61884106, 0.29487453, 0.59337726, 0.30765986, 0.18555197,\n",
       "        0.21442982, 0.31533062, 0.21442982, 0.31695779, 0.27734692,\n",
       "        0.265345  ],\n",
       "       [0.28912294, 0.28793857, 0.46087838, 0.43604073, 0.61884106,\n",
       "        0.        , 0.24295535, 0.04969236, 0.2795449 , 0.47007258,\n",
       "        0.28912294, 0.51428566, 0.28912294, 0.2127886 , 0.35362943,\n",
       "        0.26898542],\n",
       "       [0.03698586, 0.05828233, 0.26108654, 0.12857747, 0.29487453,\n",
       "        0.24295535, 0.        , 0.20318734, 0.05706489, 0.17599254,\n",
       "        0.03698586, 0.2247812 , 0.03698586, 0.0570696 , 0.09556672,\n",
       "        0.04310105],\n",
       "       [0.25193276, 0.2462537 , 0.4245239 , 0.39022886, 0.59337726,\n",
       "        0.04969236, 0.20318734, 0.        , 0.22165314, 0.48769584,\n",
       "        0.25193276, 0.46022342, 0.25193276, 0.17201598, 0.30369664,\n",
       "        0.23509538],\n",
       "       [0.06137651, 0.08165383, 0.32277567, 0.18845351, 0.30765986,\n",
       "        0.2795449 , 0.05706489, 0.22165314, 0.        , 0.17940662,\n",
       "        0.06137651, 0.21977961, 0.06137651, 0.06913059, 0.1170144 ,\n",
       "        0.06265498],\n",
       "       [0.10265558, 0.12835235, 0.31535623, 0.2240498 , 0.18555197,\n",
       "        0.47007258, 0.17599254, 0.48769584, 0.17940662, 0.        ,\n",
       "        0.10265558, 0.28209937, 0.10265558, 0.17560303, 0.19911596,\n",
       "        0.16141143],\n",
       "       [0.        , 0.02532057, 0.21259921, 0.09560514, 0.21442982,\n",
       "        0.28912294, 0.03698586, 0.25193276, 0.06137651, 0.10265558,\n",
       "        0.        , 0.16356582, 0.        , 0.04198024, 0.05565788,\n",
       "        0.02620876],\n",
       "       [0.16356582, 0.19513871, 0.31711056, 0.20454349, 0.31533062,\n",
       "        0.51428566, 0.2247812 , 0.46022342, 0.21977961, 0.28209937,\n",
       "        0.16356582, 0.        , 0.16356582, 0.23339028, 0.19923636,\n",
       "        0.18413389],\n",
       "       [0.        , 0.02532057, 0.21259921, 0.09560514, 0.21442982,\n",
       "        0.28912294, 0.03698586, 0.25193276, 0.06137651, 0.10265558,\n",
       "        0.        , 0.16356582, 0.        , 0.04198024, 0.05565788,\n",
       "        0.02620876],\n",
       "       [0.04198024, 0.07070561, 0.23522575, 0.15245731, 0.31695779,\n",
       "        0.2127886 , 0.0570696 , 0.17201598, 0.06913059, 0.17560303,\n",
       "        0.04198024, 0.23339028, 0.04198024, 0.        , 0.09651704,\n",
       "        0.04917112],\n",
       "       [0.05565788, 0.09237612, 0.24525823, 0.12452867, 0.27734692,\n",
       "        0.35362943, 0.09556672, 0.30369664, 0.1170144 , 0.19911596,\n",
       "        0.05565788, 0.19923636, 0.05565788, 0.09651704, 0.        ,\n",
       "        0.07475073],\n",
       "       [0.02620876, 0.05156929, 0.25797033, 0.12808538, 0.265345  ,\n",
       "        0.26898542, 0.04310105, 0.23509538, 0.06265498, 0.16141143,\n",
       "        0.02620876, 0.18413389, 0.02620876, 0.04917112, 0.07475073,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity matrix has a shape of 16 x 16 as expected with each cell corresponding to the similarity between two users. Now we will write a prediction function which will predict the values in the user-question matrix. We will only consider the top n items which are similar to a item to make predictions.. In this formula we don't need normalise the ratings of users questions as we are using questions to make predictions instead of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\hat{x}_{k,m} = \\frac{\\sum\\limits_{i_b} sim_i(i_m, i_b) (x_{k,b}) }{\\sum\\limits_{i_b}|sim_i(i_m, i_b)|}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_item_item(train_matrix, item_similarity, n_similar=100):\n",
    "    similar_n = item_similarity.argsort()[:,-n_similar:][:,::-1]\n",
    "    print('similar_n shape: ', similar_n.shape)\n",
    "    pred = np.zeros((n_users,n_questions))\n",
    "    \n",
    "    for i,items in enumerate(similar_n):\n",
    "        similar_items_indexes = items\n",
    "        similarity_n = item_similarity[i,similar_items_indexes]\n",
    "        matrix_n = train_matrix[:,similar_items_indexes]\n",
    "        rated_items = matrix_n.dot(similarity_n)/similarity_n.sum()\n",
    "        pred[:,i]  = rated_items\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function to find the predicted ratings. Here, we are considering the top 100 users which are similar to our user and using their ratings to predict our user's ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar_n shape:  (16, 16)\n",
      "predictions shape  (100, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.14546657, 3.20310937, 4.01392796, ..., 3.04814972, 3.44896125,\n",
       "        3.06865067],\n",
       "       [2.4857618 , 2.52293562, 3.46902525, ..., 2.33114597, 2.9635371 ,\n",
       "        2.44038797],\n",
       "       [3.38059177, 3.31889216, 3.94080769, ..., 3.30634623, 3.59761161,\n",
       "        3.27619337],\n",
       "       ...,\n",
       "       [2.82965893, 2.80832809, 3.59465896, ..., 2.64067519, 3.15232378,\n",
       "        2.78518891],\n",
       "       [3.93818538, 3.93939673, 3.93904175, ..., 3.97776336, 3.84993713,\n",
       "        3.92331891],\n",
       "       [3.67029504, 3.6775919 , 3.6853785 , ..., 3.69383585, 3.7384012 ,\n",
       "        3.63263344]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_item_item(train_matrix,item_similarity,100)\n",
    "print('predictions shape ',predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider only those ratings which are not zero in the test matrix and use them to find the error in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_ratings = predictions[test_matrix.nonzero()]\n",
    "#test_truth = test_matrix[test_matrix.nonzero()]\n",
    "#math.sqrt(mean_squared_error(predicted_ratings,test_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting similar users recommendations for a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the part we get recommendations for a user based on the highest similarity with other users . Let us get predictions for the user with user id 40. I am using the predictions from the user_user collaborative filtering model for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 40\n",
    "users_prediction = predict_users(user_similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store an array of top 10 similar users for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended For user 33 is user  61\n",
      "Recommended For user 33 is user  97\n",
      "Recommended For user 33 is user  34\n",
      "Recommended For user 33 is user  71\n",
      "Recommended For user 33 is user  88\n",
      "Recommended For user 33 is user  53\n",
      "Recommended For user 33 is user  96\n",
      "Recommended For user 33 is user  78\n",
      "Recommended For user 33 is user  80\n",
      "Recommended For user 33 is user  35\n"
     ]
    }
   ],
   "source": [
    "for i in users_prediction:\n",
    "    if i[0] == 40:\n",
    "        for users in i[1]:\n",
    "            print ('Recommended For user '+str(user_id)+' is user  '+str(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go on and print the top 10 user recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting question recommendations for a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part we get recommendations for a user based on the highest predicted ratings for a particular user. Let us get predctions for the user with user id 29. I am using the predictions from the item-item collaborative filtering model for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 29\n",
    "user_ratings = predictions[user_id-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the indices of the questions in the matrix which ratings have not been assigned i.e. value is 0 and get their predticted ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3, 11], dtype=int32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unkown_indices = np.where(train_matrix[user_id-1,:] == 0)[0]\n",
    "train_unkown_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_recommendations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go on and print the top 3 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for user 29 are  : \n",
      "\n",
      "3\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('\\nRecommendations for user {} are  : \\n'.format(user_id))\n",
    "for question_id in user_recommendations.argsort()[-5:][: : -1]:\n",
    "    print(question_id +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
